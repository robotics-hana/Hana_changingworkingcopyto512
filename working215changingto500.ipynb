{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Experimentation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FWumlmcL3r0a",
        "pqJrjauP846-",
        "DGvexk_lvq1b",
        "og7YgBCLct5T",
        "Wb_jgNjdurVl",
        "vDxQ-_Ao7NBG",
        "QJqa5zAobgr2",
        "IqNWFF1wyZtE",
        "EJbgqIFEvty2",
        "WrXjUZiI5oNH",
        "P5KsYCx34JdT",
        "PdPUGj0iCqX9",
        "hGZXjnnfiFU6",
        "HICnX_kEQDhR",
        "CKl_IU1q4yeE",
        "WDa_hakb42II",
        "ieuJPBse44cA"
      ],
      "gpuType": "L4"
    },
    "interpreter": {
      "hash": "26284b83044cf6d18497d2f2bcb8891a6475cbd87428bcdc4981d4fbeeb38628"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWumlmcL3r0a"
      },
      "source": [
        "# Load Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "yat"
      ],
      "metadata": {
        "id": "u4ppKRCyKTAT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf8Iv5caGLEe",
        "outputId": "a04802c6-79d6-435f-b9ad-33e7215302ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install extra packages needed for this notebook\n",
        "!pip install -q pyunpack patool rarfile rioxarray\n",
        "\n",
        "# --- Imports ---\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import pathlib\n",
        "import requests\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from rasterio.warp import reproject, Resampling\n",
        "from rasterio.windows import Window\n",
        "import PIL\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import *\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import pyunpack\n",
        "from rarfile import RarFile\n",
        "import rioxarray as rxr\n",
        "\n",
        "from sklearn.metrics import *\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv2D, Conv2DTranspose, MaxPooling2D,\n",
        "    Dropout, BatchNormalization, Activation, UpSampling2D,\n",
        "    concatenate, add, multiply,\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "g6QqYr9jKwcr"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjNYvVXlC6Ja"
      },
      "source": [
        "# --- 0. Setup: imports & paths ---\n",
        "\n",
        "# Folder where GEE exports were saved\n",
        "GEE_DIR = '/content/drive/MyDrive/GEE_Iraq'\n",
        "\n",
        "# Where to save tiles\n",
        "OUT_IMG_DIR = '/content/tiles/images'\n",
        "OUT_MSK_DIR = '/content/tiles/masks'\n",
        "\n",
        "os.makedirs(OUT_IMG_DIR, exist_ok=True)\n",
        "os.makedirs(OUT_MSK_DIR, exist_ok=True)\n",
        "\n",
        "TILE_SIZE = 512   # UNet input tile size\n",
        "MIN_WATER_PIXELS = 50  # skip almost-all-land tiles (adjust as you like)\n",
        "\n"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def align_mask_to_image(img_path, mask_path):\n",
        "    \"\"\"\n",
        "    Returns (img_arr, mask_arr, profile) where:\n",
        "      img_arr:  (H, W, 4)\n",
        "      mask_arr: (H, W) with values 0/1\n",
        "    \"\"\"\n",
        "    with rasterio.open(img_path) as src_img:\n",
        "        img = src_img.read()  # (bands, H, W)\n",
        "        img_profile = src_img.profile\n",
        "\n",
        "    with rasterio.open(mask_path) as src_msk:\n",
        "        msk = src_msk.read(1)  # (H2, W2)\n",
        "\n",
        "        # If shapes + transforms match, no reprojection needed\n",
        "        if (src_msk.transform == img_profile['transform'] and\n",
        "            src_msk.width == img_profile['width'] and\n",
        "            src_msk.height == img_profile['height']):\n",
        "            mask_resampled = msk\n",
        "        else:\n",
        "            # Reproject to match image grid\n",
        "            mask_resampled = np.zeros((img_profile['height'], img_profile['width']), dtype=np.float32)\n",
        "\n",
        "            reproject(\n",
        "                source=msk,\n",
        "                destination=mask_resampled,\n",
        "                src_transform=src_msk.transform,\n",
        "                src_crs=src_msk.crs,\n",
        "                dst_transform=img_profile['transform'],\n",
        "                dst_crs=img_profile['crs'],\n",
        "                resampling=Resampling.nearest\n",
        "            )\n",
        "\n",
        "    # Move image channels last: (bands, H, W) -> (H, W, bands)\n",
        "    img_arr = np.transpose(img, (1, 2, 0)).astype(np.float32)\n",
        "\n",
        "    # Ensure mask is 0/1\n",
        "    mask_arr = (mask_resampled > 0.5).astype(np.uint8)\n",
        "\n",
        "    return img_arr, mask_arr, img_profile\n"
      ],
      "metadata": {
        "id": "x7ku80U8hlfO"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tile_image_and_mask(img_arr, mask_arr, base_name,\n",
        "                        tile_size=TILE_SIZE,\n",
        "                        min_water_pixels=MIN_WATER_PIXELS):\n",
        "    \"\"\"\n",
        "    Cuts image & mask into tiles, saves non-empty ones as .npy.\n",
        "    \"\"\"\n",
        "    H, W, C = img_arr.shape\n",
        "    tile_id = 0\n",
        "\n",
        "    for row in range(0, H, tile_size):\n",
        "        for col in range(0, W, tile_size):\n",
        "            if row + tile_size > H or col + tile_size > W:\n",
        "                continue  # skip incomplete edge tiles (optional)\n",
        "\n",
        "            img_tile = img_arr[row:row+tile_size, col:col+tile_size, :]\n",
        "            msk_tile = mask_arr[row:row+tile_size, col:col+tile_size]\n",
        "\n",
        "            # Skip tiles with almost no water\n",
        "            if msk_tile.sum() < min_water_pixels:\n",
        "                continue\n",
        "\n",
        "            img_out_path = os.path.join(\n",
        "                OUT_IMG_DIR, f\"{base_name}_tile_{tile_id:04d}.npy\"\n",
        "            )\n",
        "            msk_out_path = os.path.join(\n",
        "                OUT_MSK_DIR, f\"{base_name}_tile_{tile_id:04d}.npy\"\n",
        "            )\n",
        "\n",
        "            np.save(img_out_path, img_tile)\n",
        "            np.save(msk_out_path, msk_tile)\n",
        "\n",
        "            tile_id += 1\n",
        "\n",
        "    print(f\"{base_name}: saved {tile_id} tiles.\")\n"
      ],
      "metadata": {
        "id": "VM8RiaodhmbT"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find all S2 images\n",
        "s2_files = sorted(glob.glob(os.path.join(GEE_DIR, '*_s2_4band.tif')))\n",
        "\n",
        "for s2_path in s2_files:\n",
        "    base = os.path.basename(s2_path).replace('_s2_4band.tif', '')\n",
        "    mask_path = os.path.join(GEE_DIR, base + '_gsw_water.tif')\n",
        "\n",
        "    if not os.path.exists(mask_path):\n",
        "        print(f\"⚠️ No mask for {base}, skipping.\")\n",
        "        continue\n",
        "\n",
        "    print(f\"Processing {base}...\")\n",
        "\n",
        "    img_arr, mask_arr, profile = align_mask_to_image(s2_path, mask_path)\n",
        "\n",
        "    # Simple normalisation (optional – adjust to your UNet)\n",
        "    # Example: Sentinel-2 often scaled by 10,000\n",
        "    img_arr = img_arr / 3000.0  # or 10000.0 depending on stretch\n",
        "\n",
        "    tile_image_and_mask(img_arr, mask_arr, base)\n"
      ],
      "metadata": {
        "id": "LHobeK9BhqD-",
        "outputId": "43021066-a183-439f-fda2-a457eadc22ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Dukan_2017...\n",
            "Dukan_2017: saved 28 tiles.\n",
            "Processing Dukan_2021...\n",
            "Dukan_2021: saved 27 tiles.\n",
            "Processing Habbaniyah_2017...\n",
            "Habbaniyah_2017: saved 31 tiles.\n",
            "Processing Habbaniyah_2021...\n",
            "Habbaniyah_2021: saved 37 tiles.\n",
            "Processing Razzaza_2017...\n",
            "Razzaza_2017: saved 40 tiles.\n",
            "Processing Razzaza_2021...\n",
            "Razzaza_2021: saved 53 tiles.\n",
            "Processing darbandikhan_2017...\n",
            "darbandikhan_2017: saved 20 tiles.\n",
            "Processing darbandikhan_2021...\n",
            "darbandikhan_2021: saved 17 tiles.\n",
            "Processing tharthar_2017...\n",
            "tharthar_2017: saved 113 tiles.\n",
            "Processing tharthar_2021...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def align_mask_to_image(img_path, mask_path):\n",
        "    \"\"\"\n",
        "    Returns cleaned:\n",
        "      img_arr: (H, W, 4)\n",
        "      mask_arr: (H, W)\n",
        "    \"\"\"\n",
        "    import rasterio\n",
        "    import numpy as np\n",
        "    from rasterio.warp import reproject, Resampling\n",
        "\n",
        "    # ---- READ IMAGE ----\n",
        "    with rasterio.open(img_path) as src_img:\n",
        "        img = src_img.read().astype('float32')   # (bands, H, W)\n",
        "        img_profile = src_img.profile\n",
        "\n",
        "    # ---- CLEAN IMAGE ----\n",
        "    img = np.nan_to_num(img, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "    # ---- READ MASK ----\n",
        "    with rasterio.open(mask_path) as src_msk:\n",
        "        msk = src_msk.read(1).astype('float32')\n",
        "\n",
        "        # CLEAN MASK\n",
        "        msk = np.nan_to_num(msk, nan=0.0)\n",
        "\n",
        "        # If shapes match, no reprojection needed\n",
        "        if (src_msk.transform == img_profile['transform'] and\n",
        "            src_msk.width == img_profile['width'] and\n",
        "            src_msk.height == img_profile['height']):\n",
        "            mask_resampled = msk\n",
        "        else:\n",
        "            # Reproject to image grid\n",
        "            mask_resampled = np.zeros((img_profile['height'], img_profile['width']),\n",
        "                                      dtype='float32')\n",
        "\n",
        "            reproject(\n",
        "                source=msk,\n",
        "                destination=mask_resampled,\n",
        "                src_transform=src_msk.transform,\n",
        "                src_crs=src_msk.crs,\n",
        "                dst_transform=img_profile['transform'],\n",
        "                dst_crs=img_profile['crs'],\n",
        "                resampling=Resampling.nearest\n",
        "            )\n",
        "\n",
        "    # Move channels last\n",
        "    img_arr = np.transpose(img, (1,2,0))   # (H, W, 4)\n",
        "\n",
        "    # Ensure mask is 0/1\n",
        "    mask_arr = (mask_resampled > 0.5).astype(np.uint8)\n",
        "\n",
        "    return img_arr, mask_arr, img_profile\n"
      ],
      "metadata": {
        "id": "MWLLz57lkVtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for s2_path in s2_files:\n",
        "    base = os.path.basename(s2_path).replace('_s2_4band.tif', '')\n",
        "    mask_path = os.path.join(GEE_DIR, base + '_gsw_water.tif')\n",
        "\n",
        "    if not os.path.exists(mask_path):\n",
        "        print(f\"⚠ No mask for {base}, skipping\")\n",
        "        continue\n",
        "\n",
        "    print(f\"Processing {base}...\")\n",
        "\n",
        "    img_arr, mask_arr, profile = align_mask_to_image(s2_path, mask_path)\n",
        "\n",
        "    # DO NOT NORMALISE HERE\n",
        "    tile_image_and_mask(img_arr, mask_arr, base)\n"
      ],
      "metadata": {
        "id": "7YH82fVmkXur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob, os\n",
        "\n",
        "OUT_IMG_DIR = '/content/tiles/images'\n",
        "OUT_MSK_DIR = '/content/tiles/masks'\n",
        "\n",
        "img_tile_path = sorted(glob.glob(os.path.join(OUT_IMG_DIR, 'tharthar_2021*.npy')))[0]\n",
        "msk_tile_path = img_tile_path.replace('/images/', '/masks/')\n",
        "\n",
        "img_tile = np.load(img_tile_path).astype('float32')   # (256,256,4)\n",
        "msk_tile = np.load(msk_tile_path).astype('float32')   # (256,256)\n",
        "\n",
        "# Safety clean (just in case)\n",
        "img_tile = np.nan_to_num(img_tile, nan=0)\n",
        "\n",
        "# Build RGB (raw S2 reflectance)\n",
        "rgb = img_tile[..., [2,1,0]]  # B4,B3,B2\n",
        "\n",
        "# Simple scaling for display\n",
        "rgb_disp = rgb / np.max(rgb)  # auto-scale 0–1\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(rgb_disp)\n",
        "plt.title(\"Raw RGB\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(rgb_disp)\n",
        "plt.imshow(msk_tile, alpha=0.4)\n",
        "plt.title(\"RGB + Mask\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "s5M_38fekhQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, os\n",
        "import numpy as np\n",
        "\n",
        "OUT_IMG_DIR = '/content/tiles/images'\n",
        "OUT_MSK_DIR = '/content/tiles/masks'\n",
        "\n",
        "tharthar_tiles = sorted(glob.glob(os.path.join(OUT_IMG_DIR, 'tharthar_2021*.npy')))\n",
        "print(\"Found tiles:\", len(tharthar_tiles))\n",
        "\n",
        "best_path = None\n",
        "best_nonzero_frac = -1\n",
        "\n",
        "for path in tharthar_tiles:\n",
        "    tile = np.load(path).astype('float32')\n",
        "    # count non-zero pixels in red band (B4, index 2)\n",
        "    red = tile[..., 2]\n",
        "    nonzero_frac = np.count_nonzero(red) / red.size\n",
        "\n",
        "    if nonzero_frac > best_nonzero_frac:\n",
        "        best_nonzero_frac = nonzero_frac\n",
        "        best_path = path\n",
        "\n",
        "print(\"Best tile:\", best_path)\n",
        "print(\"Best nonzero fraction:\", best_nonzero_frac)\n"
      ],
      "metadata": {
        "id": "4JbUJlktk4IZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img_tile_path = best_path\n",
        "img_tile = np.load(img_tile_path).astype('float32')   # (256,256,4)\n",
        "\n",
        "# extract B4,B3,B2\n",
        "rgb = img_tile[..., [2,1,0]]\n",
        "\n",
        "# simple robust scaling\n",
        "rgb_disp = rgb - np.nanmin(rgb)\n",
        "rgb_disp = rgb_disp / (np.nanmax(rgb_disp) + 1e-6)\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.imshow(rgb_disp)\n",
        "plt.title(f\"Raw RGB – {os.path.basename(img_tile_path)}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "19g6W-H1k7V-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mask path\n",
        "msk_tile_path = img_tile_path.replace('/images/', '/masks/')\n",
        "msk_tile = np.load(msk_tile_path).astype('float32')\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(msk_tile)\n",
        "plt.title(\"Mask\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(rgb_disp)\n",
        "plt.imshow(msk_tile, alpha=0.4)\n",
        "plt.title(\"RGB + Mask\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7IYUjbNOk-vs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqJrjauP846-"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTEOTi_qwD0G"
      },
      "source": [
        "'''\n",
        "  Returns an image plot of mask prediction\n",
        "'''\n",
        "\n",
        "def reconstruct_image(model, image, rounded=False):\n",
        "\n",
        "  # Find model prediction\n",
        "  reconstruction = model.predict(image).reshape(image.shape[1], image.shape[2])\n",
        "  # Standardise between 0-1\n",
        "  reconstruction = reconstruction/np.max(reconstruction)\n",
        "\n",
        "  # Round to 0-1, binary pixel-by-pixel classification\n",
        "  if rounded:\n",
        "    reconstruction = np.round(reconstruction)\n",
        "\n",
        "  # Plot reconstructed mask (prediction)\n",
        "  plt.imshow(reconstruction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxUiu0_OxMlo"
      },
      "source": [
        "'''\n",
        "  Returns array of mask prediction, given model and image\n",
        "'''\n",
        "def reconstruct_array(model, image, rounded=False):\n",
        "\n",
        "  # Find model prediction\n",
        "  reconstruction = model.predict(image).reshape(image.shape[1], image.shape[2])\n",
        "\n",
        "  if rounded:\n",
        "    reconstruction = np.round(reconstruction)\n",
        "\n",
        "  return reconstruction # Returns array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prjIhHN-r4o5"
      },
      "source": [
        "'''\n",
        "  Metric functions for evaluation\n",
        "'''\n",
        "\n",
        "def score_eval(model, image, mask): # Gives score of mask vs prediction\n",
        "  if type(image) != list:\n",
        "    reconstruction = model.predict(image).reshape(mask.shape[1], mask.shape[2])\n",
        "    reconstruction = np.round(reconstruction).flatten()\n",
        "\n",
        "    return accuracy_score(mask.flatten(), reconstruction)\n",
        "\n",
        "  else: # If a list of images input, find accuracy for each\n",
        "    scores = []\n",
        "    for i in range(len(image)):\n",
        "      reconstruction = model.predict(image[i].reshape(1, 512, 512, 3))\n",
        "      reconstruction = np.round(reconstruction).flatten()\n",
        "\n",
        "      scores.append(accuracy_score(mask[i].flatten(), reconstruction))\n",
        "\n",
        "    return scores\n",
        "\n",
        "def score_eval2(model, image, mask): # Gives score of mask vs prediction\n",
        "  if type(image) != list:\n",
        "    reconstruction = model.predict(image).reshape(mask.shape[1], mask.shape[2])\n",
        "    reconstruction = np.round(reconstruction).flatten()\n",
        "\n",
        "    return accuracy_score(mask.flatten(), reconstruction)\n",
        "\n",
        "  else: # If a list of images input, find accuracy for each\n",
        "    scores = []\n",
        "    for i in range(len(image)):\n",
        "      reconstruction = model.predict(image[i].reshape(1, 512, 512, 4))\n",
        "      reconstruction = np.round(reconstruction).flatten()\n",
        "\n",
        "      scores.append(accuracy_score(mask[i].flatten(), reconstruction))\n",
        "\n",
        "    return scores\n",
        "\n",
        "def recall_eval(model, image, mask): # Find recall score\n",
        "  if type(image) != list:\n",
        "    reconstruction = model.predict(image).reshape(mask.shape[1], mask.shape[2])\n",
        "    reconstruction = np.round(reconstruction).flatten()\n",
        "\n",
        "    return recall_score(mask.flatten(), reconstruction, average='weighted')\n",
        "\n",
        "  else: # If a list of images input, find accuracy for each\n",
        "    recall = []\n",
        "    for i in range(len(image)):\n",
        "        reconstruction = model.predict(image[i]).reshape(mask[i].shape[1], mask[i].shape[2])\n",
        "        reconstruction = np.round(reconstruction).flatten()\n",
        "\n",
        "        recall.append(recall_score(mask[i].flatten(), reconstruction, average='weighted'))\n",
        "\n",
        "    return recall\n",
        "\n",
        "def precision_eval(model, image, mask): # Find precision score\n",
        "  if type(image) != list:\n",
        "    reconstruction = model.predict(image).reshape(mask.shape[1], mask.shape[2])\n",
        "    reconstruction = np.round(reconstruction).flatten()\n",
        "\n",
        "    return precision_score(mask.flatten(), reconstruction, average='weighted')\n",
        "\n",
        "  else: # If a list of images input, find accuracy for each\n",
        "    precision = []\n",
        "    for i in range(len(image)):\n",
        "        reconstruction = model.predict(image[i]).reshape(mask[i].shape[1], mask[i].shape[2])\n",
        "        reconstruction = np.round(reconstruction).flatten()\n",
        "\n",
        "        precision.append(precision_score(mask[i].flatten(), reconstruction, average='weighted'))\n",
        "\n",
        "    return precision\n",
        "\n",
        "def f1_score_eval(model, image, mask): # Find F1-score\n",
        "    prec = np.mean(precision_eval(model, image, mask))\n",
        "    rec = np.mean(recall_eval(model, image, mask))\n",
        "\n",
        "    if prec + rec == 0:\n",
        "        return 0\n",
        "\n",
        "    return 2 * (prec * rec) / (prec + rec)\n",
        "\n",
        "def f1_score_eval_basic(precision, recall):\n",
        "    prec = np.mean(precision)\n",
        "    rec = np.mean(recall)\n",
        "\n",
        "    if prec + rec == 0:\n",
        "        return 0\n",
        "\n",
        "    return 2 * (prec * rec) / (prec + rec)\n",
        "\n",
        "def produce_mask(image): # Outputs rounded image (binary)\n",
        "  return np.round(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mz6o3t3sveL"
      },
      "source": [
        "# Ingest and Process 4-band Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og7YgBCLct5T"
      },
      "source": [
        "## 4-band Amazon dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_dir2 = \"/content/tiles_dataset/\"\n",
        "\n",
        "folders = [\n",
        "    \"Training/image\",\n",
        "    \"Training/label\",\n",
        "    \"Validation/images\",\n",
        "    \"Validation/masks\",\n",
        "    \"Test/image\",\n",
        "    \"Test/mask\",\n",
        "]\n",
        "\n",
        "for f in folders:\n",
        "    os.makedirs(os.path.join(base_dir2, f), exist_ok=True)\n",
        "\n",
        "print(\"Created dataset folders at:\", base_dir2)\n",
        "\n"
      ],
      "metadata": {
        "id": "vwKy9p8JmoMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "TILES_IMG = \"/content/tiles/images/\"\n",
        "TILES_MSK = \"/content/tiles/masks/\"\n",
        "\n",
        "img_paths = sorted(glob.glob(os.path.join(TILES_IMG, \"*.npy\")))\n",
        "msk_paths = [p.replace(\"/images/\", \"/masks/\") for p in img_paths]\n",
        "\n",
        "print(\"Total tiles found:\", len(img_paths))\n",
        "\n",
        "# 70% train, 15% validation, 15% test\n",
        "X_train, X_tmp, y_train, y_tmp = train_test_split(\n",
        "    img_paths, msk_paths, test_size=0.30, random_state=42\n",
        ")\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_tmp, y_tmp, test_size=0.50, random_state=42\n",
        ")\n",
        "\n",
        "def copy_pairs(img_list, msk_list, img_dest, msk_dest):\n",
        "    for img, msk in zip(img_list, msk_list):\n",
        "        shutil.copy(img, img_dest)\n",
        "        shutil.copy(msk, msk_dest)\n",
        "\n",
        "copy_pairs(X_train, y_train, base_dir2 + \"Training/image/\", base_dir2 + \"Training/label/\")\n",
        "copy_pairs(X_val,   y_val,   base_dir2 + \"Validation/images/\", base_dir2 + \"Validation/masks/\")\n",
        "copy_pairs(X_test,  y_test,  base_dir2 + \"Test/image/\",       base_dir2 + \"Test/mask/\")\n",
        "\n",
        "print(\"Tiles copied into Train / Val / Test successfully.\")\n"
      ],
      "metadata": {
        "id": "FARySbo-o5UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "train_img_dir = base_dir2 + \"Training/image/\"\n",
        "train_msk_dir = base_dir2 + \"Training/label/\"\n",
        "\n",
        "training_images2 = []\n",
        "training_masks2 = []\n",
        "\n",
        "training_files = sorted(os.listdir(train_img_dir))\n",
        "\n",
        "for n in training_files:\n",
        "    img = np.load(train_img_dir + n).astype('float32')       # (256,256,4)\n",
        "    msk = np.load(train_msk_dir + n).astype('float32')       # (256,256)\n",
        "\n",
        "    # normalise image per tile\n",
        "    img = img - np.nanmin(img)\n",
        "    img = img / (np.nanmax(img) + 1e-6)\n",
        "\n",
        "    # binarise + add channel dim\n",
        "    msk = (msk > 0.5).astype('float32')[..., np.newaxis]     # (256,256,1)\n",
        "\n",
        "    training_images2.append(img)\n",
        "    training_masks2.append(msk)\n",
        "\n",
        "training_images2 = np.stack(training_images2)\n",
        "training_masks2  = np.stack(training_masks2)\n",
        "\n",
        "print(\"Train X:\", training_images2.shape)\n",
        "print(\"Train y:\", training_masks2.shape)\n"
      ],
      "metadata": {
        "id": "ClIeg6GxpE-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCp3t2JSyQ9O"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDxQ-_Ao7NBG"
      },
      "source": [
        "## U-Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--tUx5qNR0Q4"
      },
      "source": [
        "'''\n",
        "  Convolutional block with set parameters and activation layer after\n",
        "'''\n",
        "\n",
        "def convBlock(input, filters, kernel, kernel_init='he_normal', act='relu', transpose=False):\n",
        "  if transpose == False:\n",
        "    #conv = ZeroPadding2D((1,1))(input)\n",
        "    conv = Conv2D(filters, kernel, padding = 'same', kernel_initializer = kernel_init)(input)\n",
        "  else:\n",
        "    #conv = ZeroPadding2D((1,1))(input)\n",
        "    conv = Conv2DTranspose(filters, kernel, padding = 'same', kernel_initializer = kernel_init)(input)\n",
        "\n",
        "  conv = Activation(act)(conv)\n",
        "  return conv\n",
        "\n",
        "'''\n",
        "  U-Net model\n",
        "'''\n",
        "\n",
        "def UNet(trained_weights = None, input_size = (512,512,3), drop_rate = 0.25, lr=0.0001):\n",
        "\n",
        "    ## Can add pretrained weights by specifying 'trained_weights'\n",
        "\n",
        "    # Input layer\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    ## Contraction phase\n",
        "    conv1 = convBlock(inputs, 64, 3)\n",
        "    conv1 = convBlock(conv1, 64, 3)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = convBlock(pool1, 128, 3)\n",
        "    conv2 = convBlock(conv2, 128, 3)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    #drop2 = Dropout(drop_rate)(pool2)\n",
        "\n",
        "    conv3 = convBlock(pool2, 256, 3)\n",
        "    conv3 = convBlock(conv3, 256, 3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    #drop3 = Dropout(drop_rate)(pool3)\n",
        "\n",
        "    conv4 = convBlock(pool3, 512, 3)\n",
        "    conv4 = convBlock(conv4, 512, 3)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "    #drop4 = Dropout(drop_rate)(pool4)\n",
        "\n",
        "    conv5 = convBlock(pool4, 1024, 3)\n",
        "    conv5 = convBlock(conv5, 1024, 3)\n",
        "\n",
        "    ## Expansion phase\n",
        "    up6 = (Conv2DTranspose(512, kernel_size=2, strides=2, kernel_initializer='he_normal')(conv5))\n",
        "    merge6 = concatenate([conv4,up6])\n",
        "    conv6 = convBlock(merge6, 512, 3)\n",
        "    conv6 = convBlock(conv6, 512, 3)\n",
        "    #conv6 = Dropout(drop_rate)(conv6)\n",
        "\n",
        "    up7 = (Conv2DTranspose(256, kernel_size=2, strides=2, kernel_initializer='he_normal')(conv6))\n",
        "    merge7 = concatenate([conv3,up7])\n",
        "    conv7 = convBlock(merge7, 256, 3)\n",
        "    conv7 = convBlock(conv7, 256, 3)\n",
        "    #conv7 = Dropout(drop_rate)(conv7)\n",
        "\n",
        "    up8 = (Conv2DTranspose(128, kernel_size=2, strides=2, kernel_initializer='he_normal')(conv7))\n",
        "    merge8 = concatenate([conv2,up8])\n",
        "    conv8 = convBlock(merge8, 128, 3)\n",
        "    conv8 = convBlock(conv8, 128, 3)\n",
        "    #conv8 = Dropout(drop_rate)(conv8)\n",
        "\n",
        "    up9 = (Conv2DTranspose(64, kernel_size=2, strides=2, kernel_initializer='he_normal')(conv8))\n",
        "    merge9 = concatenate([conv1,up9])\n",
        "    conv9 = convBlock(merge9, 64, 3)\n",
        "    conv9 = convBlock(conv9, 64, 3)\n",
        "\n",
        "    # Output layer\n",
        "    conv10 = convBlock(conv9, 1, 1, act='sigmoid')\n",
        "\n",
        "    model = Model(inputs, conv10)\n",
        "\n",
        "    model.compile(optimizer = Adam(learning_rate = lr), loss = 'binary_crossentropy', metrics = ['accuracy', 'mse'])\n",
        "\n",
        "    if trained_weights != None:\n",
        "    \tmodel.load_weights(trained_weights)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD6fODjlcLdG"
      },
      "source": [
        "# Print model layers and number of parameters\n",
        "UNet().summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJqa5zAobgr2"
      },
      "source": [
        "## Attention U-Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3uY93JpT_OZ"
      },
      "source": [
        "'''\n",
        "  Convolutional block with two conv layers and two activation layers\n",
        "'''\n",
        "\n",
        "def convBlock2(input, filters, kernel, kernel_init='he_normal', act='relu', transpose=False):\n",
        "  if transpose == False:\n",
        "    conv = Conv2D(filters, kernel, padding = 'same', kernel_initializer = kernel_init)(input)\n",
        "    conv = Activation(act)(conv)\n",
        "    conv = Conv2D(filters, kernel, padding = 'same', kernel_initializer = kernel_init)(conv)\n",
        "    conv = Activation(act)(conv)\n",
        "  else:\n",
        "    conv = Conv2DTranspose(filters, kernel, padding = 'same', kernel_initializer = kernel_init)(input)\n",
        "    conv = Activation(act)(conv)\n",
        "    conv = Conv2DTranspose(filters, kernel, padding = 'same', kernel_initializer = kernel_init)(conv)\n",
        "    conv = Activation(act)(conv)\n",
        "\n",
        "  return conv\n",
        "\n",
        "'''\n",
        "  Attention block/mechanism\n",
        "'''\n",
        "def attention_block(x, gating, inter_shape, drop_rate=0.25):\n",
        "\n",
        "    # Find shape of inputs\n",
        "    shape_x = K.int_shape(x)\n",
        "    shape_g = K.int_shape(gating)\n",
        "\n",
        "    ## Process x vector and gating signal\n",
        "    # x vector input and processing\n",
        "    theta_x = Conv2D(inter_shape, kernel_size = 1, strides = 1, padding='same', kernel_initializer='he_normal', activation=None)(x)\n",
        "    theta_x = MaxPooling2D((2,2))(theta_x)\n",
        "    shape_theta_x = K.int_shape(theta_x)\n",
        "\n",
        "    # gating signal \"\"\n",
        "    phi_g = Conv2D(inter_shape, kernel_size = 1, strides = 1, padding='same', kernel_initializer='he_normal', activation=None)(gating)\n",
        "    shape_phi_g = K.int_shape(phi_g)\n",
        "\n",
        "    # Add components\n",
        "    concat_xg = add([phi_g, theta_x])\n",
        "    act_xg = Activation('relu')(concat_xg)\n",
        "\n",
        "    # Apply convolution\n",
        "    psi = Conv2D(1, kernel_size = 1, strides = 1, padding='same', kernel_initializer='he_normal', activation=None)(act_xg)\n",
        "\n",
        "    # Apply sigmoid activation\n",
        "    sigmoid_xg = Activation('sigmoid')(psi)\n",
        "    shape_sigmoid = K.int_shape(sigmoid_xg)\n",
        "\n",
        "    # UpSample and resample to correct size\n",
        "    upsample_psi = UpSampling2D(\n",
        "        interpolation='bilinear',\n",
        "        size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2])\n",
        "    )(sigmoid_xg)\n",
        "\n",
        "    # No tf.broadcast_to – Keras will broadcast automatically in multiply()\n",
        "    y = multiply([upsample_psi, x])\n",
        "\n",
        "\n",
        "    return y\n",
        "\n",
        "\n",
        "'''\n",
        "  Attention U-Net model\n",
        "'''\n",
        "\n",
        "def UNetAM(trained_weights = None, input_size = (512,512,3), drop_rate = 0.25, lr=0.0001, filter_base=16):\n",
        "\n",
        "    ## Can add pretrained weights by specifying 'trained_weights'\n",
        "\n",
        "    # Input layer\n",
        "    inputs = Input(input_size, batch_size=1)\n",
        "\n",
        "    ## Contraction phase\n",
        "    conv = convBlock2(inputs, filter_base, 3)\n",
        "    #conv0 = Dropout(drop_rate)(conv0)\n",
        "\n",
        "    conv0 = MaxPooling2D(pool_size=(2, 2))(conv)\n",
        "    conv0 = convBlock2(conv0, 2 * filter_base, 3)\n",
        "\n",
        "    pool0 = MaxPooling2D(pool_size=(2, 2))(conv0)\n",
        "    conv1 = convBlock2(pool0, 4 * filter_base, 3)\n",
        "    #conv1 = Dropout(drop_rate)(conv1)\n",
        "\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = convBlock2(pool1, 8 * filter_base, 3)\n",
        "    #conv2 = Dropout(drop_rate)(conv2)\n",
        "\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = convBlock2(pool2, 16 * filter_base, 3)\n",
        "    #conv3 = Dropout(drop_rate)(conv3)\n",
        "\n",
        "    ## Expansion phase\n",
        "    up4 = (Conv2DTranspose(8 * filter_base, kernel_size=2, strides=2, kernel_initializer='he_normal')(conv3))\n",
        "    merge4 = attention_block(conv2, conv3, 8 * filter_base, drop_rate) # Attention gate\n",
        "    conv4 = concatenate([up4, merge4])\n",
        "    conv4 = convBlock2(conv4, 8 * filter_base, 3)\n",
        "\n",
        "    up5 = (Conv2DTranspose(4 * filter_base, kernel_size=2, strides=2, kernel_initializer='he_normal')(conv4))\n",
        "    merge5 = attention_block(conv1, conv4, 4 * filter_base, drop_rate) # Attention gate\n",
        "    conv5 = concatenate([up5, merge5])\n",
        "    conv5 = convBlock2(conv5, 4 * filter_base, 3)\n",
        "\n",
        "    up6 = (Conv2DTranspose(2 * filter_base, kernel_size=2, strides=2, kernel_initializer='he_normal')(conv5))\n",
        "    merge6 = attention_block(conv0, conv5, 2 * filter_base, drop_rate) # Attention gate\n",
        "    conv6 = concatenate([up6, merge6])\n",
        "    conv6 = convBlock2(conv6, 2 * filter_base, 3)\n",
        "\n",
        "    up7 = (Conv2DTranspose(1 * filter_base, kernel_size=2, strides=2, kernel_initializer='he_normal')(conv6))\n",
        "    merge7 = attention_block(conv, conv6, 1 * filter_base, drop_rate) # Attention gate\n",
        "    conv7 = concatenate([up7, merge7])\n",
        "    conv7 = concatenate([up7, conv])\n",
        "    conv7 = convBlock2(conv7, 1 * filter_base, 3)\n",
        "\n",
        "    ## Output layer\n",
        "    out = convBlock(conv7, 1, 1, act='sigmoid')\n",
        "\n",
        "    model = Model(inputs, out)\n",
        "\n",
        "    model.compile(optimizer = Adam(learning_rate = lr), loss = binary_crossentropy, metrics = ['accuracy', 'mse'])\n",
        "\n",
        "    if trained_weights != None:\n",
        "    \tmodel.load_weights(trained_weights)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2fZD22p5xsF"
      },
      "source": [
        "# Print model layers and number of parameters\n",
        "UNetAM().summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5KsYCx34JdT"
      },
      "source": [
        "# Train on 4-band data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdPUGj0iCqX9"
      },
      "source": [
        "## Train on 4-band Amazon data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGZXjnnfiFU6"
      },
      "source": [
        "### U-Net"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Build 4-band UNet for 256×256 tiles\n",
        "model_unet_4band = UNet(input_size=(256,256,4), lr=0.0001)\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((training_images2, training_masks2))\n",
        "train_ds = train_ds.shuffle(2000).batch(BATCH_SIZE).repeat()\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((validation_images2, validation_masks2))\n",
        "val_ds = val_ds.batch(BATCH_SIZE)\n",
        "\n",
        "\n",
        "# Save best model by validation accuracy\n",
        "save_model_4band = ModelCheckpoint(\n",
        "    'unet-4band-lakes.keras',\n",
        "    monitor='val_accuracy',\n",
        "    verbose=1,\n",
        "    save_best_only=True\n",
        ")\n",
        "# Train directly on NumPy arrays\n",
        "history_4band = model_unet_4band.fit(\n",
        "    train_ds,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=30,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[save_model_4band],\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "oCmLPfpwsFSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5Sf1pmCDI-c"
      },
      "source": [
        "# Save model history\n",
        "np.save('unet-4d-history.npy',model_unet_4band.history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CM86ZMtryOi2"
      },
      "source": [
        "# Copy models to drive\n",
        "!cp unet-4band-lakes.keras /content/drive/MyDrive/Diss/\n",
        "!cp unet-4d-history.npy drive/MyDrive/Diss/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HICnX_kEQDhR"
      },
      "source": [
        "### Attention U-Net"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((training_images2, training_masks2))\n",
        "train_ds = train_ds.shuffle(2000).batch(BATCH_SIZE).repeat()\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((validation_images2, validation_masks2))\n",
        "val_ds = val_ds.batch(BATCH_SIZE)\n",
        "\n",
        "# ---------------------------\n",
        "# 2) Build Attention U-Net (4-band, 256x256)\n",
        "#    UNetAM must already be defined in your notebook\n",
        "# ---------------------------\n",
        "model_attention_unet_4band = UNetAM(\n",
        "    input_size=(256, 256, 4),\n",
        "    filter_base=16,\n",
        "    lr=0.0005\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "# 3) Checkpoint callback (attention model)\n",
        "# ---------------------------\n",
        "save_model_4band_attention = ModelCheckpoint(\n",
        "    'unet-attention-4band-lakes.keras',\n",
        "    monitor='val_accuracy',\n",
        "    verbose=1,\n",
        "    save_best_only=True\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "# 4) Train with generator (same style as original Amazon code)\n",
        "# ---------------------------\n",
        "history_attention_4band = model_attention_unet_4band.fit(\n",
        "    train_ds,\n",
        "    steps_per_epoch=100,       # like your original: more iterations per epoch\n",
        "    epochs=60,                 # same as your old attention UNet\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[save_model_4band_attention],\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "tVjAOV6ztmeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU7s-wvYQgy7"
      },
      "source": [
        "# Save model history\n",
        "np.save('unet-attention-4d-history.npy',model_attention_unet_4band.history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8jeWN9XfEO-"
      },
      "source": [
        "# Copy models to drive\n",
        "!cp unet-attention-4band-lakes.keras /content/drive/MyDrive/Diss/\n",
        "!cp unet-attention-4d-history.npy drive/MyDrive/Diss/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wb_jgNjdurVl"
      },
      "source": [
        "## 4-band Atlantic Forest dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "azfzKAKfEvNC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANUhzzdQvOaL"
      },
      "source": [
        "# Ingest images and normalise\n",
        "\n",
        "## Training images\n",
        "training_images_list3 = os.listdir(r\"{}Training/image/\".format(base_dir3))[0:250]\n",
        "training_masks_list3 = []\n",
        "training_images3 = []\n",
        "for n in training_images_list3:\n",
        "  training_masks_list3.append(n)\n",
        "  a = (np.array(rxr.open_rasterio(r\"{}Training/image/{}\".format(base_dir3,n))))\n",
        "  a = (a-np.min(a)) / (np.max(a)-np.min(a))\n",
        "  training_images3.append(a)\n",
        "\n",
        "## Training masks\n",
        "training_masks3 = []\n",
        "for n in training_masks_list3:\n",
        "  a = (np.array(rxr.open_rasterio(r\"{}Training/label/{}\".format(base_dir3,n))))\n",
        "  training_masks3.append(a)\n",
        "\n",
        "## Test images\n",
        "test_images_list3 = os.listdir(r\"{}Test/image/\".format(base_dir3))\n",
        "test_masks_list3 = []\n",
        "test_images3 = []\n",
        "for n in test_images_list3:\n",
        "  test_masks_list3.append(n)\n",
        "  a = (np.array(rxr.open_rasterio(r\"{}Test/image/{}\".format(base_dir3,n))))\n",
        "  a = (a-np.min(a)) / (np.max(a)-np.min(a))\n",
        "  test_images3.append(a)\n",
        "\n",
        "## Test masks\n",
        "test_masks3 = []\n",
        "for n in test_masks_list3:\n",
        "  a = (np.array(rxr.open_rasterio(r\"{}Test/mask/{}\".format(base_dir3,n))))\n",
        "  test_masks3.append(a)\n",
        "\n",
        "## Validation images\n",
        "validation_images_list3 = os.listdir(r\"{}Validation/images/\".format(base_dir3))\n",
        "validation_masks_list3 = []\n",
        "validation_images3 = []\n",
        "for n in validation_images_list3:\n",
        "  validation_masks_list3.append(n)\n",
        "  a = (np.array(rxr.open_rasterio(r\"{}Validation/images/{}\".format(base_dir3,n))))\n",
        "  a = (a-np.min(a)) / (np.max(a)-np.min(a))\n",
        "  validation_images3.append(a)\n",
        "\n",
        "## Validation masks\n",
        "validation_masks3 = []\n",
        "for n in validation_masks_list3:\n",
        "  a = (np.array(rxr.open_rasterio(r\"{}Validation/masks/{}\".format(base_dir3,n))))\n",
        "  validation_masks3.append(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L31I43OJxMVU"
      },
      "source": [
        "# Pre-process data, reshaping and transposing\n",
        "for i in range(len(training_images3)):\n",
        "  training_images3[i] = training_images3[i].astype('float32')\n",
        "  training_images3[i] = training_images3[i].T\n",
        "\n",
        "for i in range(len(training_masks3)):\n",
        "  training_masks3[i] = training_masks3[i].reshape(1,512,512,1)\n",
        "  training_masks3[i] = training_masks3[i].T\n",
        "\n",
        "for i in range(len(validation_images3)):\n",
        "  validation_images3[i] = validation_images3[i].astype('float32')\n",
        "  validation_images3[i] = validation_images3[i].T\n",
        "\n",
        "for i in range(len(validation_masks3)):\n",
        "  validation_masks3[i] = validation_masks3[i].reshape(1,512,512,1)\n",
        "  validation_masks3[i] = validation_masks3[i].T\n",
        "\n",
        "for i in range(len(test_images3)):\n",
        "  test_images3[i] = test_images3[i].astype('float32')\n",
        "  test_images3[i] = test_images3[i].T\n",
        "\n",
        "for i in range(len(test_masks3)):\n",
        "  test_masks3[i] = test_masks3[i].reshape(1,512,512,1)\n",
        "  test_masks3[i] = test_masks3[i].T\n",
        "\n",
        "\n",
        "for i in range(len(training_images3)):\n",
        "  training_images3[i] = training_images3[i].reshape(-1,512,512,4)\n",
        "\n",
        "for i in range(len(validation_images3)):\n",
        "  validation_images3[i] = validation_images3[i].reshape(-1,512,512,4)\n",
        "\n",
        "for i in range(len(test_images3)):\n",
        "  test_images3[i] = test_images3[i].reshape(-1,512,512,4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn73cK3QE9fN"
      },
      "source": [
        "# Plot example training image first band\n",
        "plt.imshow(training_images3[0].reshape(512,512,4)[:,:,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n-tBTsjyL5q"
      },
      "source": [
        "# Create TensorFlow datasets for training and validation sets\n",
        "train_df_4band_atlantic = tf.data.Dataset.from_tensor_slices((training_images3[0:250], training_masks3[0:250]))\n",
        "validation_df_4band_atlantic = tf.data.Dataset.from_tensor_slices((validation_images3, validation_masks3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-JXc78rQLaL"
      },
      "source": [
        "# Import Models and Compute Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LI5RTFiZD9W-"
      },
      "source": [
        "# **Iraq Lake Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuWpNDuLZS2W"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Load 4-band UNet models\n",
        "unet_4d = load_model('unet-4band-lakes.keras')\n",
        "attention_unet_4d = load_model('unet-attention-4band-lakes.keras')\n",
        "\n",
        "# Load histories\n",
        "unet_4d_history = np.load('unet-4d-history.npy', allow_pickle=True).item()\n",
        "attention_unet_4d_history = np.load('unet-attention-4d-history.npy', allow_pickle=True).item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwDcH3DJQLaO"
      },
      "source": [
        "# Plot accuracy and loss for U-Net\n",
        "\n",
        "## Accuracy\n",
        "plt.plot(unet_4d_history['accuracy'])\n",
        "plt.plot(unet_4d_history['val_accuracy'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "## Loss\n",
        "plt.plot(unet_4d_history['loss'])\n",
        "plt.plot(unet_4d_history['val_loss'])\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mcn0YjbZpPL"
      },
      "source": [
        "# Plot accuracy and loss for Attention U-Net\n",
        "\n",
        "## Accuracy\n",
        "plt.plot(attention_unet_4d_history['accuracy'])\n",
        "plt.plot(attention_unet_4d_history['val_accuracy'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "## Loss\n",
        "plt.plot(attention_unet_4d_history['loss'])\n",
        "plt.plot(attention_unet_4d_history['val_loss'])\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "\n",
        "def score_eval2(model, images, masks):\n",
        "    \"\"\"\n",
        "    Evaluate model on a whole batch of images + masks.\n",
        "    images: (N, H, W, C)\n",
        "    masks:  (N, H, W) or (N, H, W, 1)\n",
        "    \"\"\"\n",
        "    # Predict on all images\n",
        "    preds = model.predict(images)\n",
        "\n",
        "    # Drop channel dimension if it's (N, H, W, 1)\n",
        "    if preds.ndim == 4 and preds.shape[-1] == 1:\n",
        "        preds = preds[..., 0]\n",
        "    if masks.ndim == 4 and masks.shape[-1] == 1:\n",
        "        masks = masks[..., 0]\n",
        "\n",
        "    # Binarise predictions (0/1)\n",
        "    preds_bin = np.round(preds).astype(np.uint8)\n",
        "\n",
        "    # Flatten everything to 1D for global scores\n",
        "    y_pred = preds_bin.flatten()\n",
        "    y_true = masks.astype(np.uint8).flatten()\n",
        "\n",
        "    # Sanity check\n",
        "    assert y_pred.shape == y_true.shape, f\"Shape mismatch: {y_pred.shape} vs {y_true.shape}\"\n",
        "\n",
        "    scores = {\n",
        "        \"accuracy\":  accuracy_score(y_true, y_pred),\n",
        "        \"f1\":        f1_score(y_true, y_pred),\n",
        "        \"precision\": precision_score(y_true, y_pred),\n",
        "        \"recall\":    recall_score(y_true, y_pred),\n",
        "    }\n",
        "    return scores\n"
      ],
      "metadata": {
        "id": "vrRfgpa9Vgrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1V4qoM4ZtjE"
      },
      "source": [
        "# Scores of each model\n",
        "unet_4d_score = (score_eval2(unet_4d, validation_images2, validation_masks2))\n",
        "am_unet_4d_score = (score_eval2(attention_unet_4d, validation_images2, validation_masks2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "import numpy as np\n",
        "\n",
        "def precision_eval(model, images, masks):\n",
        "    \"\"\"\n",
        "    Global precision over a batch of images.\n",
        "    images: (N, H, W, C)\n",
        "    masks:  (N, H, W) or (N, H, W, 1)\n",
        "    \"\"\"\n",
        "    preds = model.predict(images)\n",
        "\n",
        "    # Drop channel dim if present\n",
        "    if preds.ndim == 4 and preds.shape[-1] == 1:\n",
        "        preds = preds[..., 0]\n",
        "    if masks.ndim == 4 and masks.shape[-1] == 1:\n",
        "        masks = masks[..., 0]\n",
        "\n",
        "    # Binarise predictions\n",
        "    preds_bin = np.round(preds).astype(np.uint8)\n",
        "\n",
        "    # Flatten\n",
        "    y_pred = preds_bin.flatten()\n",
        "    y_true = masks.astype(np.uint8).flatten()\n",
        "\n",
        "    assert y_pred.shape == y_true.shape, f\"Shape mismatch: {y_pred.shape} vs {y_true.shape}\"\n",
        "\n",
        "    return precision_score(y_true, y_pred)\n",
        "\n",
        "\n",
        "def recall_eval(model, images, masks):\n",
        "    \"\"\"\n",
        "    Global recall over a batch of images.\n",
        "    images: (N, H, W, C)\n",
        "    masks:  (N, H, W) or (N, H, W, 1)\n",
        "    \"\"\"\n",
        "    preds = model.predict(images)\n",
        "\n",
        "    # Drop channel dim if present\n",
        "    if preds.ndim == 4 and preds.shape[-1] == 1:\n",
        "        preds = preds[..., 0]\n",
        "    if masks.ndim == 4 and masks.shape[-1] == 1:\n",
        "        masks = masks[..., 0]\n",
        "\n",
        "    # Binarise predictions\n",
        "    preds_bin = np.round(preds).astype(np.uint8)\n",
        "\n",
        "    # Flatten\n",
        "    y_pred = preds_bin.flatten()\n",
        "    y_true = masks.astype(np.uint8).flatten()\n",
        "\n",
        "    assert y_pred.shape == y_true.shape, f\"Shape mismatch: {y_pred.shape} vs {y_true.shape}\"\n",
        "\n",
        "    return recall_score(y_true, y_pred)\n"
      ],
      "metadata": {
        "id": "ZQbq9sw0V0Sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVcI_yk4Z80x"
      },
      "source": [
        "# Precision and recall of each model\n",
        "unet_4d_precision = (precision_eval(unet_4d, validation_images2, validation_masks2))\n",
        "am_unet_4d_precision = (precision_eval(attention_unet_4d, validation_images2, validation_masks2))\n",
        "\n",
        "unet_4d_recall = (recall_eval(unet_4d, validation_images2, validation_masks2))\n",
        "am_unet_4d_recall = (recall_eval(attention_unet_4d, validation_images2, validation_masks2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvarhjO1aTX_"
      },
      "source": [
        "# F1-scores of each model\n",
        "unet_4d_f1_score = (f1_score_eval_basic(unet_4d_precision, unet_4d_recall))\n",
        "am_unet_4d_f1_score = (f1_score_eval_basic(am_unet_4d_precision, am_unet_4d_recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Htyl7Pi-aU88"
      },
      "source": [
        "print(\"UNet accuracy:\", unet_4d_score[\"accuracy\"])\n",
        "print(\"UNet f1:\", unet_4d_score[\"f1\"])\n",
        "print(\"UNet precision:\", unet_4d_score[\"precision\"])\n",
        "print(\"UNet recall:\", unet_4d_score[\"recall\"])\n",
        "\n",
        "print(\"\\nAttention UNet accuracy:\", am_unet_4d_score[\"accuracy\"])\n",
        "print(\"Attention UNet f1:\", am_unet_4d_score[\"f1\"])\n",
        "print(\"Attention UNet precision:\", am_unet_4d_score[\"precision\"])\n",
        "print(\"Attention UNet recall:\", am_unet_4d_score[\"recall\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geaOxWrpaWi9"
      },
      "source": [
        "# Print precision eval results for each model\n",
        "print('U-Net precision: ', np.mean(unet_4d_precision), np.std(unet_4d_precision))\n",
        "print('Attention U-Net precision: ', np.mean(am_unet_4d_precision), np.std(am_unet_4d_precision))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mpmu_7EaYEH"
      },
      "source": [
        "# Print recall eval results for each model\n",
        "print('U-Net recall: ', np.mean(unet_4d_recall), np.std(unet_4d_recall))\n",
        "print('Attention U-Net recall: ', np.mean(am_unet_4d_recall), np.std(am_unet_4d_recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0NXQpR2aYZG"
      },
      "source": [
        "# Print f1-score eval results for each model\n",
        "print('U-Net F1-score: ', np.mean(unet_4d_f1_score))\n",
        "print('Attention U-Net F1-score: ', np.mean(am_unet_4d_f1_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# IMPORTS\n",
        "# ==========================================\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# ==========================================\n",
        "# LOAD MODELS (from your Drive or local)\n",
        "# ==========================================\n",
        "unet_4d = load_model('/content/drive/MyDrive/Diss/unet-4band-lakes.keras')\n",
        "attention_unet_4d = load_model('/content/drive/MyDrive/Diss/unet-attention-4band-lakes.keras')\n",
        "\n",
        "print(\"Models loaded successfully.\")\n",
        "\n",
        "# ==========================================\n",
        "# USE YOUR REAL VARIABLE NAMES\n",
        "# validation_images2 = your images\n",
        "# validation_masks2  = your masks\n",
        "# ==========================================\n",
        "\n",
        "# Convert lists to numpy arrays if needed\n",
        "validation_images2 = np.array(validation_images2)   # shape: (N,256,256,4)\n",
        "validation_masks2  = np.array(validation_masks2)    # shape: (N,256,256,1)\n",
        "\n",
        "print(\"Validation data:\", validation_images2.shape, validation_masks2.shape)\n",
        "\n",
        "# ==========================================\n",
        "# HELPER FUNCTIONS\n",
        "# ==========================================\n",
        "def to_rgb(img4):\n",
        "    \"\"\" Convert 4-band tile → RGB using B4,B3,B2 \"\"\"\n",
        "    rgb = img4[..., [2, 1, 0]].astype(\"float32\")\n",
        "    rgb = rgb - np.nanmin(rgb)\n",
        "    rgb = rgb / (np.nanmax(rgb) + 1e-6)\n",
        "    return rgb\n",
        "\n",
        "def overlay(rgb, mask_bin, alpha=0.4):\n",
        "    plt.imshow(rgb)\n",
        "    plt.imshow(mask_bin, cmap=\"cool\", alpha=alpha)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "# ==========================================\n",
        "# PICK TILE INDEX (CHANGE THIS)\n",
        "# ==========================================\n",
        "tile_idx = 145\n",
        "\n",
        "tile_img = validation_images2[tile_idx]          # (256,256,4)\n",
        "tile_mask = validation_masks2[tile_idx, ..., 0]  # (256,256)\n",
        "\n",
        "rgb = to_rgb(tile_img)\n",
        "\n",
        "# ==========================================\n",
        "# MODEL PREDICTIONS\n",
        "# ==========================================\n",
        "unet_pred = unet_4d.predict(tile_img[np.newaxis, ...])[0, ..., 0]\n",
        "attn_pred = attention_unet_4d.predict(tile_img[np.newaxis, ...])[0, ..., 0]\n",
        "\n",
        "unet_pred_bin = np.round(unet_pred)\n",
        "attn_pred_bin = np.round(attn_pred)\n",
        "\n",
        "print(\"Predictions complete for tile:\", tile_idx)\n",
        "\n",
        "# ==========================================\n",
        "# FIGURE 1 — RGB, GT, UNET, ATTENTION UNET\n",
        "# ==========================================\n",
        "plt.figure(figsize=(14, 8))\n",
        "\n",
        "plt.subplot(2,2,1)\n",
        "plt.imshow(rgb)\n",
        "plt.title(\"Original RGB Tile\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.imshow(tile_mask, cmap=\"viridis\")\n",
        "plt.title(\"Ground Truth Mask\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(2,2,3)\n",
        "plt.imshow(unet_pred_bin, cmap=\"viridis\")\n",
        "plt.title(\"U-Net Prediction\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(2,2,4)\n",
        "plt.imshow(attn_pred_bin, cmap=\"viridis\")\n",
        "plt.title(\"Attention U-Net Prediction\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"lake_segmentation_panels.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Saved: lake_segmentation_panels.png\")\n",
        "\n",
        "# ==========================================\n",
        "# FIGURE 2 — OVERLAYS\n",
        "# ==========================================\n",
        "plt.figure(figsize=(15,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "overlay(rgb, tile_mask)\n",
        "plt.title(\"RGB + Ground Truth\")\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "overlay(rgb, unet_pred_bin)\n",
        "plt.title(\"RGB + U-Net Prediction\")\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "overlay(rgb, attn_pred_bin)\n",
        "plt.title(\"RGB + Attention U-Net Prediction\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"lake_segmentation_overlays.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Saved: lake_segmentation_overlays.png\")\n"
      ],
      "metadata": {
        "id": "Zhi0B24i-_Mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beZYrcZdzE0c"
      },
      "source": [
        "### Amazon on unseen Atlantic data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7LTlQvAzH8K"
      },
      "source": [
        "# Score\n",
        "unet_amazon_on_atlantic_score = score_eval2(unet_4d, validation_images3+test_images3, validation_masks3+test_masks3)\n",
        "am_unet_amazon_on_atlantic_score = score_eval2(attention_unet_4d, validation_images3+test_images3, validation_masks3+test_masks3)\n",
        "\n",
        "# Precision\n",
        "unet_amazon_on_atlantic_precision = (precision_eval(unet_4d, validation_images3+test_images3, validation_masks3+test_masks3))\n",
        "am_unet_amazon_on_atlantic_precision = (precision_eval(attention_unet_4d, validation_images3+test_images3, validation_masks3+test_masks3))\n",
        "\n",
        "# Recall\n",
        "unet_amazon_on_atlantic_recall = (recall_eval(unet_4d, validation_images3+test_images3, validation_masks3+test_masks3))\n",
        "am_unet_amazon_on_atlantic_recall = (recall_eval(attention_unet_4d, validation_images3+test_images3, validation_masks3+test_masks3))\n",
        "\n",
        "# F1-scores of each model\n",
        "unet_amazon_on_atlantic_f1_score = (f1_score_eval_basic(unet_amazon_on_atlantic_precision, unet_amazon_on_atlantic_recall))\n",
        "am_unet_amazon_on_atlantic_f1_score = (f1_score_eval_basic(am_unet_amazon_on_atlantic_precision, am_unet_amazon_on_atlantic_recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtAbkWSY0Xnn"
      },
      "source": [
        "# Print metrics\n",
        "print('U-Net score: ', np.mean(unet_amazon_on_atlantic_score), np.std(unet_amazon_on_atlantic_score))\n",
        "print('Attention U-Net score: ', np.mean(am_unet_amazon_on_atlantic_score), np.std(am_unet_amazon_on_atlantic_score))\n",
        "\n",
        "print('U-Net precision: ', np.mean(unet_amazon_on_atlantic_precision), np.std(unet_amazon_on_atlantic_precision))\n",
        "print('Attention U-Net precision: ', np.mean(am_unet_amazon_on_atlantic_precision), np.std(am_unet_amazon_on_atlantic_precision))\n",
        "\n",
        "print('U-Net recall: ', np.mean(unet_amazon_on_atlantic_recall), np.std(unet_amazon_on_atlantic_recall))\n",
        "print('Attention U-Net recall: ', np.mean(am_unet_amazon_on_atlantic_recall), np.std(am_unet_amazon_on_atlantic_recall))\n",
        "\n",
        "print('U-Net F1-score: ', unet_amazon_on_atlantic_f1_score)\n",
        "print('Attention U-Net F1-score: ', am_unet_amazon_on_atlantic_f1_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRQOG9uUECcu"
      },
      "source": [
        "### Atlantic Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQIc0XDmEFND"
      },
      "source": [
        "# Load 4-dim models and history stats\n",
        "attention_unet_4d_atlantic = load_model('unet-attention-4d-atlantic.keras')\n",
        "unet_4d_atlantic = load_model('unet-4d-atlantic.keras')\n",
        "\n",
        "unet_4d_atlantic_history = np.load('unet-4d-atlantic-history.npy', allow_pickle='TRUE').item()\n",
        "attention_unet_4d_atlantic_history = np.load('unet-attention-4d-atlantic-history.npy', allow_pickle='TRUE').item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4YBSQxjEWLc"
      },
      "source": [
        "# Plot accuracy and loss for U-Net\n",
        "\n",
        "## Accuracy\n",
        "plt.plot(unet_4d_atlantic_history['accuracy'])\n",
        "plt.plot(unet_4d_atlantic_history['val_accuracy'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "## Loss\n",
        "plt.plot(unet_4d_atlantic_history['loss'])\n",
        "plt.plot(unet_4d_atlantic_history['val_loss'])\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCFSJmMzEaR5"
      },
      "source": [
        "# Plot accuracy and loss for Attention U-Net\n",
        "\n",
        "## Accuracy\n",
        "plt.plot(attention_unet_4d_atlantic_history['accuracy'])\n",
        "plt.plot(attention_unet_4d_atlantic_history['val_accuracy'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "## Loss\n",
        "plt.plot(attention_unet_4d_atlantic_history['loss'])\n",
        "plt.plot(attention_unet_4d_atlantic_history['val_loss'])\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNxllVnXEhvb"
      },
      "source": [
        "# Scores of each model\n",
        "unet_4d_atlantic_score = (score_eval2(unet_4d_atlantic, validation_images3, validation_masks3))\n",
        "am_unet_4d_atlantic_score = (score_eval2(attention_unet_4d_atlantic, validation_images3, validation_masks3))\n",
        "\n",
        "# Precision and recall of each model\n",
        "unet_4d_atlantic_precision = (precision_eval(unet_4d_atlantic, validation_images3, validation_masks3))\n",
        "am_unet_4d_atlantic_precision = (precision_eval(attention_unet_4d_atlantic, validation_images3, validation_masks3))\n",
        "\n",
        "unet_4d_atlantic_recall = (recall_eval(unet_4d_atlantic, validation_images3, validation_masks3))\n",
        "am_unet_4d_atlantic_recall = (recall_eval(attention_unet_4d_atlantic, validation_images3, validation_masks3))\n",
        "\n",
        "# F1-scores of each model\n",
        "unet_4d_atlantic_f1_score = (f1_score_eval_basic(unet_4d_atlantic_precision, unet_4d_atlantic_recall))\n",
        "am_unet_4d_atlantic_f1_score = (f1_score_eval_basic(am_unet_4d_atlantic_precision, am_unet_4d_atlantic_recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuoQ8__mE9Ut"
      },
      "source": [
        "# Print metrics\n",
        "print('U-Net score: ', np.mean(unet_4d_atlantic_score), np.std(unet_4d_atlantic_score))\n",
        "print('Attention U-Net score: ', np.mean(am_unet_4d_atlantic_score), np.std(am_unet_4d_atlantic_score))\n",
        "\n",
        "print('U-Net precision: ', np.mean(unet_4d_atlantic_precision), np.std(unet_4d_atlantic_precision))\n",
        "print('Attention U-Net precision: ', np.mean(am_unet_4d_atlantic_precision), np.std(am_unet_4d_atlantic_precision))\n",
        "\n",
        "print('U-Net recall: ', np.mean(unet_4d_atlantic_recall), np.std(unet_4d_atlantic_recall))\n",
        "print('Attention U-Net recall: ', np.mean(am_unet_4d_atlantic_recall), np.std(am_unet_4d_atlantic_recall))\n",
        "\n",
        "print('U-Net F1-score: ', unet_4d_atlantic_f1_score)\n",
        "print('Attention U-Net F1-score: ', am_unet_4d_atlantic_f1_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LttV4BY-FO9Y"
      },
      "source": [
        "### Atlantic on unseen Amazon data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0mUcfs7FWCn"
      },
      "source": [
        "# Score\n",
        "unet_atlantic_on_amazon_score = score_eval2(unet_4d_atlantic, validation_images2+test_images2, validation_masks2+test_masks2)\n",
        "am_unet_atlantic_on_amazon_score = score_eval2(attention_unet_4d_atlantic, validation_images2+test_images2, validation_masks2+test_masks2)\n",
        "\n",
        "# Precision\n",
        "unet_atlantic_on_amazon_precision = (precision_eval(unet_4d_atlantic, validation_images2+test_images2, validation_masks2+test_masks2))\n",
        "am_unet_atlantic_on_amazon_precision = (precision_eval(attention_unet_4d_atlantic, validation_images2+test_images2, validation_masks2+test_masks2))\n",
        "\n",
        "# Recall\n",
        "unet_atlantic_on_amazon_recall = (recall_eval(unet_4d_atlantic, validation_images2+test_images2, validation_masks2+test_masks2))\n",
        "am_unet_atlantic_on_amazon_recall = (recall_eval(attention_unet_4d_atlantic, validation_images2+test_images2, validation_masks2+test_masks2))\n",
        "\n",
        "# F1-scores of each model\n",
        "unet_atlantic_on_amazon_f1_score = (f1_score_eval_basic(unet_atlantic_on_amazon_precision, unet_atlantic_on_amazon_recall))\n",
        "am_unet_atlantic_on_amazon_f1_score = (f1_score_eval_basic(am_unet_atlantic_on_amazon_precision, am_unet_atlantic_on_amazon_recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emaoDHfdFWfL"
      },
      "source": [
        "# Print metrics\n",
        "print('U-Net score: ', np.mean(unet_atlantic_on_amazon_score), np.std(unet_atlantic_on_amazon_score))\n",
        "print('Attention U-Net score: ', np.mean(am_unet_atlantic_on_amazon_score), np.std(am_unet_atlantic_on_amazon_score))\n",
        "\n",
        "print('U-Net precision: ', np.mean(unet_atlantic_on_amazon_precision), np.std(unet_atlantic_on_amazon_precision))\n",
        "print('Attention U-Net precision: ', np.mean(am_unet_atlantic_on_amazon_precision), np.std(am_unet_atlantic_on_amazon_precision))\n",
        "\n",
        "print('U-Net recall: ', np.mean(unet_atlantic_on_amazon_recall), np.std(unet_atlantic_on_amazon_recall))\n",
        "print('Attention U-Net recall: ', np.mean(am_unet_atlantic_on_amazon_recall), np.std(am_unet_atlantic_on_amazon_recall))\n",
        "\n",
        "print('U-Net F1-score: ', unet_atlantic_on_amazon_f1_score)\n",
        "print('Attention U-Net F1-score: ', am_unet_atlantic_on_amazon_f1_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EWGiqFzlsrv"
      },
      "source": [
        "### Amazon and Atlantic unseen test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Txs1Av6GpAlu"
      },
      "source": [
        "# Amazon trained model on Amazon test data\n",
        "# Scores of each model\n",
        "unet_4d_score_test = (score_eval2(unet_4d, test_images2, test_masks2))\n",
        "am_unet_4d_score_test = (score_eval2(attention_unet_4d, test_images2, test_masks2))\n",
        "\n",
        "# Precision and recall of each model\n",
        "unet_4d_precision_test = (precision_eval(unet_4d, test_images2, test_masks2))\n",
        "am_unet_4d_precision_test = (precision_eval(attention_unet_4d, test_images2, test_masks2))\n",
        "\n",
        "unet_4d_recall_test = (recall_eval(unet_4d, test_images2, test_masks2))\n",
        "am_unet_4d_recall_test = (recall_eval(attention_unet_4d, test_images2, test_masks2))\n",
        "\n",
        "# F1-scores of each model\n",
        "unet_4d_f1_score_test = (f1_score_eval_basic(unet_4d_precision_test, unet_4d_recall_test))\n",
        "am_unet_4d_f1_score_test = (f1_score_eval_basic(am_unet_4d_precision_test, am_unet_4d_recall_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Njk-zCC7lw8_"
      },
      "source": [
        "# Atlantic trained model on Atlantic test data\n",
        "# Scores of each model\n",
        "unet_4d_atlantic_score_test = (score_eval2(unet_4d_atlantic, test_images3, test_masks3))\n",
        "am_unet_4d_atlantic_score_test = (score_eval2(attention_unet_4d_atlantic, test_images3, test_masks3))\n",
        "\n",
        "# Precision and recall of each model\n",
        "unet_4d_atlantic_precision_test = (precision_eval(unet_4d_atlantic, test_images3, test_masks3))\n",
        "am_unet_4d_atlantic_precision_test = (precision_eval(attention_unet_4d_atlantic, test_images3, test_masks3))\n",
        "\n",
        "unet_4d_atlantic_recall_test = (recall_eval(unet_4d_atlantic, test_images3, test_masks3))\n",
        "am_unet_4d_atlantic_recall_test = (recall_eval(attention_unet_4d_atlantic, test_images3, test_masks3))\n",
        "\n",
        "# F1-scores of each model\n",
        "unet_4d_atlantic_f1_score_test = (f1_score_eval_basic(unet_4d_atlantic_precision_test, unet_4d_atlantic_recall_test))\n",
        "am_unet_4d_atlantic_f1_score_test = (f1_score_eval_basic(am_unet_4d_atlantic_precision_test, am_unet_4d_atlantic_recall_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSCJGrpkppSA"
      },
      "source": [
        "# Print metrics for Amazon on Amazon Test set\n",
        "print('U-Net score: ', np.mean(unet_4d_score_test), np.std(unet_4d_score_test))\n",
        "print('Attention U-Net score: ', np.mean(am_unet_4d_score_test), np.std(am_unet_4d_score_test))\n",
        "\n",
        "print('U-Net precision: ', np.mean(unet_4d_precision_test), np.std(unet_4d_precision_test))\n",
        "print('Attention U-Net precision: ', np.mean(am_unet_4d_precision_test), np.std(am_unet_4d_precision_test))\n",
        "\n",
        "print('U-Net recall: ', np.mean(unet_4d_recall_test), np.std(unet_4d_recall_test))\n",
        "print('Attention U-Net recall: ', np.mean(am_unet_4d_recall_test), np.std(am_unet_4d_recall_test))\n",
        "\n",
        "print('U-Net F1-score: ', unet_4d_f1_score_test)\n",
        "print('Attention U-Net F1-score: ', am_unet_4d_f1_score_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnXkLvzuqpYv"
      },
      "source": [
        "# Print metrics for Atlantic on Atlantic Test set\n",
        "print('U-Net score: ', np.mean(unet_4d_atlantic_score_test), np.std(unet_4d_atlantic_score_test))\n",
        "print('Attention U-Net score: ', np.mean(am_unet_4d_atlantic_score_test), np.std(am_unet_4d_atlantic_score_test))\n",
        "\n",
        "print('U-Net precision: ', np.mean(unet_4d_atlantic_precision_test), np.std(unet_4d_atlantic_precision_test))\n",
        "print('Attention U-Net precision: ', np.mean(am_unet_4d_atlantic_precision_test), np.std(am_unet_4d_atlantic_precision_test))\n",
        "\n",
        "print('U-Net recall: ', np.mean(unet_4d_atlantic_recall_test), np.std(unet_4d_atlantic_recall_test))\n",
        "print('Attention U-Net recall: ', np.mean(am_unet_4d_atlantic_recall_test), np.std(am_unet_4d_atlantic_recall_test))\n",
        "\n",
        "print('U-Net F1-score: ', unet_4d_atlantic_f1_score_test)\n",
        "print('Attention U-Net F1-score: ', am_unet_4d_atlantic_f1_score_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PIo2l0n1XOt"
      },
      "source": [
        "# Produce metric datasets for export"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hj2L_RE7149Q"
      },
      "source": [
        "## 4-band Amazon data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMbXcGo31682"
      },
      "source": [
        "scores_4d = [unet_4d_score, am_unet_4d_score]\n",
        "precision_4d = [unet_4d_precision, am_unet_4d_precision]\n",
        "recall_4d = [unet_4d_recall, am_unet_4d_recall]\n",
        "f1_scores_4d = [unet_4d_f1_score, am_unet_4d_f1_score]\n",
        "\n",
        "metrics_4d = {'classifier': ['U-Net', 'Attention U-Net'],\n",
        "              'accuracy': [np.mean(n) for n in scores_4d],\n",
        "              'precision': [np.mean(n) for n in precision_4d],\n",
        "              'recall': [np.mean(n) for n in recall_4d],\n",
        "              'f1_score': [np.mean(n) for n in f1_scores_4d],\n",
        "              'accuracy_std': [np.std(n) for n in scores_4d],\n",
        "              'precision_std': [np.std(n) for n in precision_4d],\n",
        "              'recall_std': [np.std(n) for n in recall_4d]\n",
        "              }\n",
        "metrics_4d = pd.DataFrame(metrics_4d)\n",
        "metrics_4d.to_csv('metrics_4d_amazon.csv')\n",
        "metrics_4d.to_csv('/content/drive/MyDrive/Diss/metrics_4d_amazon.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eYZ0RkN17XE"
      },
      "source": [
        "## 4-band Atlantic Forest data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edIeklLV19Zi"
      },
      "source": [
        "scores_4d_atl = [unet_4d_atlantic_score, am_unet_4d_atlantic_score]\n",
        "precision_4d_atl = [unet_4d_atlantic_precision, am_unet_4d_atlantic_precision]\n",
        "recall_4d_atl = [unet_4d_atlantic_recall, am_unet_4d_atlantic_recall]\n",
        "f1_scores_4d_atl = [unet_4d_atlantic_f1_score, am_unet_4d_atlantic_f1_score]\n",
        "\n",
        "metrics_4d_atl = {'classifier': ['U-Net', 'Attention U-Net'],\n",
        "              'accuracy': [np.mean(n) for n in scores_4d_atl],\n",
        "              'precision': [np.mean(n) for n in precision_4d_atl],\n",
        "              'recall': [np.mean(n) for n in recall_4d_atl],\n",
        "              'f1_score': [np.mean(n) for n in f1_scores_4d_atl],\n",
        "              'accuracy_std': [np.std(n) for n in scores_4d_atl],\n",
        "              'precision_std': [np.std(n) for n in precision_4d_atl],\n",
        "              'recall_std': [np.std(n) for n in recall_4d_atl]\n",
        "              }\n",
        "metrics_4d_atl = pd.DataFrame(metrics_4d_atl)\n",
        "metrics_4d_atl.to_csv('metrics_4d_atlantic_forest.csv')\n",
        "metrics_4d_atl.to_csv('/content/drive/MyDrive/Diss/metrics_4d_atlantic_forest.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tF7HQghy5Qxz"
      },
      "source": [
        "## Test set data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCt9VZ3s5SSr"
      },
      "source": [
        "scores_4d_test = [unet_4d_score_test, am_unet_4d_score_test]\n",
        "precision_4d_test = [unet_4d_precision_test, am_unet_4d_precision_test]\n",
        "recall_4d_test = [unet_4d_recall_test, am_unet_4d_recall_test]\n",
        "f1_scores_4d_test = [unet_4d_f1_score_test, am_unet_4d_f1_score_test]\n",
        "\n",
        "metrics_4d_test = {'classifier': ['U-Net', 'Attention U-Net'],\n",
        "              'accuracy': [np.mean(n) for n in scores_4d_test],\n",
        "              'precision': [np.mean(n) for n in precision_4d_test],\n",
        "              'recall': [np.mean(n) for n in recall_4d_test],\n",
        "              'f1_score': [np.mean(n) for n in f1_scores_4d_test],\n",
        "              'accuracy_std': [np.std(n) for n in scores_4d_test],\n",
        "              'precision_std': [np.std(n) for n in precision_4d_test],\n",
        "              'recall_std': [np.std(n) for n in recall_4d_test]\n",
        "              }\n",
        "metrics_4d_test = pd.DataFrame(metrics_4d_test)\n",
        "metrics_4d_test.to_csv('metrics_4d_amazon_test.csv')\n",
        "metrics_4d_test.to_csv('/content/drive/MyDrive/Diss/metrics_4d_amazon_test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M127Qw5A5xUX"
      },
      "source": [
        "scores_4d_atl_test = [unet_4d_atlantic_score_test, am_unet_4d_atlantic_score_test]\n",
        "precision_4d_atl_test = [unet_4d_atlantic_precision_test, am_unet_4d_atlantic_precision_test]\n",
        "recall_4d_atl_test = [unet_4d_atlantic_recall_test, am_unet_4d_atlantic_recall_test]\n",
        "f1_scores_4d_atl_test = [unet_4d_atlantic_f1_score_test, am_unet_4d_atlantic_f1_score_test]\n",
        "\n",
        "metrics_4d_atl_test = {'classifier': ['U-Net', 'Attention U-Net'],\n",
        "              'accuracy': [np.mean(n) for n in scores_4d_atl_test],\n",
        "              'precision': [np.mean(n) for n in precision_4d_atl_test],\n",
        "              'recall': [np.mean(n) for n in recall_4d_atl_test],\n",
        "              'f1_score': [np.mean(n) for n in f1_scores_4d_atl_test],\n",
        "              'accuracy_std': [np.std(n) for n in scores_4d_atl_test],\n",
        "              'precision_std': [np.std(n) for n in precision_4d_atl_test],\n",
        "              'recall_std': [np.std(n) for n in recall_4d_atl_test]\n",
        "              }\n",
        "metrics_4d_atl_test = pd.DataFrame(metrics_4d_atl_test)\n",
        "metrics_4d_atl_test.to_csv('metrics_4d_atlantic_forest_test.csv')\n",
        "metrics_4d_atl_test.to_csv('/content/drive/MyDrive/Diss/metrics_4d_atlantic_forest_test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYkobMR86TR6"
      },
      "source": [
        "## Testing on opposite dataset (e.g. train on Amazon, test on Atlantic)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKl_IU1q4yeE"
      },
      "source": [
        "## Train on 4-band Atlantic data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDa_hakb42II"
      },
      "source": [
        "### U-Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULAHseJg403h"
      },
      "source": [
        "# Train U-Net with generator\n",
        "model_unet_4band_atlantic = UNet(input_size=(512, 512, 4), lr=0.0001)\n",
        "save_model_4band_atlantic = ModelCheckpoint('unet-4d-atlantic.keras', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "model_unet_4band_atlantic.fit(train_df_4band_atlantic, epochs = 20, validation_data = validation_df_4band_atlantic, callbacks=[save_model_4band_atlantic])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saTWiRbk5NLN"
      },
      "source": [
        "# Save model history\n",
        "np.save('unet-4d-atlantic-history.npy',model_unet_4band_atlantic.history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNIQWXYMoNi7"
      },
      "source": [
        "# Copy models to drive\n",
        "!cp unet-4d-atlantic.keras drive/MyDrive/Diss/\n",
        "!cp unet-4d-atlantic-history.npy drive/MyDrive/Diss/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieuJPBse44cA"
      },
      "source": [
        "### Attention U-Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEvQIolulSNp"
      },
      "source": [
        "# Train Attention U-Net with generator\n",
        "model_attention_unet_4band_atlantic = UNetAM(input_size=(512,512,4), filter_base=16, lr=0.0005)\n",
        "save_model_4band_attention_atlantic = ModelCheckpoint('unet-attention-4d-atlantic.keras', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "model_attention_unet_4band_atlantic.fit(train_df_4band_atlantic, epochs = 60, validation_data = validation_df_4band_atlantic, callbacks=[save_model_4band_attention_atlantic])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vYhP4_25caq"
      },
      "source": [
        "# Save model history\n",
        "np.save('unet-attention-4d-atlantic-history.npy',model_attention_unet_4band_atlantic.history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMCaWw6On6_D"
      },
      "source": [
        "# Copy models to drive\n",
        "!cp unet-attention-4d-atlantic.keras drive/MyDrive/Diss/\n",
        "!cp unet-attention-4d-atlantic-history.npy drive/MyDrive/Diss/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYz22lx-6X3V"
      },
      "source": [
        "scores_amazon_on_atlantic = [unet_amazon_on_atlantic_score, am_unet_amazon_on_atlantic_score]\n",
        "precision_amazon_on_atlantic = [unet_amazon_on_atlantic_precision, am_unet_amazon_on_atlantic_precision]\n",
        "recall_amazon_on_atlantic = [unet_amazon_on_atlantic_recall, am_unet_amazon_on_atlantic_recall]\n",
        "f1_scores_amazon_on_atlantic = [unet_amazon_on_atlantic_f1_score, am_unet_amazon_on_atlantic_f1_score]\n",
        "\n",
        "metrics_4d_amazon_on_atlantic = {'classifier': ['U-Net', 'Attention U-Net'],\n",
        "              'accuracy': [np.mean(n) for n in scores_amazon_on_atlantic],\n",
        "              'precision': [np.mean(n) for n in precision_amazon_on_atlantic],\n",
        "              'recall': [np.mean(n) for n in recall_amazon_on_atlantic],\n",
        "              'f1_score': [np.mean(n) for n in f1_scores_amazon_on_atlantic],\n",
        "              'accuracy_std': [np.std(n) for n in scores_amazon_on_atlantic],\n",
        "              'precision_std': [np.std(n) for n in precision_amazon_on_atlantic],\n",
        "              'recall_std': [np.std(n) for n in recall_amazon_on_atlantic]\n",
        "              }\n",
        "metrics_4d_amazon_on_atlantic = pd.DataFrame(metrics_4d_amazon_on_atlantic)\n",
        "metrics_4d_amazon_on_atlantic.to_csv('metrics_4d_amazon_on_atlantic.csv')\n",
        "metrics_4d_amazon_on_atlantic.to_csv('/content/drive/MyDrive/Diss/metrics_4d_amazon_on_atlantic.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OunQa23t7mwA"
      },
      "source": [
        "scores_atlantic_on_amazon = [unet_atlantic_on_amazon_score, am_unet_atlantic_on_amazon_score]\n",
        "precision_atlantic_on_amazon = [unet_atlantic_on_amazon_precision, am_unet_atlantic_on_amazon_precision]\n",
        "recall_atlantic_on_amazon = [unet_atlantic_on_amazon_recall, am_unet_atlantic_on_amazon_recall]\n",
        "f1_scores_atlantic_on_amazon = [unet_atlantic_on_amazon_f1_score, am_unet_atlantic_on_amazon_f1_score]\n",
        "\n",
        "metrics_4d_atlantic_on_amazon = {'classifier': ['U-Net', 'Attention U-Net'],\n",
        "              'accuracy': [np.mean(n) for n in scores_atlantic_on_amazon],\n",
        "              'precision': [np.mean(n) for n in precision_atlantic_on_amazon],\n",
        "              'recall': [np.mean(n) for n in recall_atlantic_on_amazon],\n",
        "              'f1_score': [np.mean(n) for n in f1_scores_atlantic_on_amazon],\n",
        "              'accuracy_std': [np.std(n) for n in scores_atlantic_on_amazon],\n",
        "              'precision_std': [np.std(n) for n in precision_atlantic_on_amazon],\n",
        "              'recall_std': [np.std(n) for n in recall_atlantic_on_amazon]\n",
        "              }\n",
        "metrics_4d_atlantic_on_amazon = pd.DataFrame(metrics_4d_atlantic_on_amazon)\n",
        "metrics_4d_atlantic_on_amazon.to_csv('metrics_4d_atlantic_on_amazon.csv')\n",
        "# Save CSV directly to Google Drive\n",
        "metrics_4d_atlantic_on_amazon.to_csv('/content/drive/MyDrive/Diss/metrics_4d_atlantic_on_amazon.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /content\n"
      ],
      "metadata": {
        "id": "F-OuU--Wucot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "hana preporocessing"
      ],
      "metadata": {
        "id": "PrzD6Z9MM_Jz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_img_dir = base_dir2 + \"Validation/images/\"\n",
        "val_msk_dir = base_dir2 + \"Validation/masks/\"\n",
        "\n",
        "validation_images2 = []\n",
        "validation_masks2 = []\n",
        "\n",
        "validation_files = sorted(os.listdir(val_img_dir))\n",
        "\n",
        "for n in validation_files:\n",
        "    img = np.load(val_img_dir + n).astype('float32')\n",
        "    msk = np.load(val_msk_dir + n).astype('float32')\n",
        "\n",
        "    img = img - np.nanmin(img)\n",
        "    img = img / (np.nanmax(img) + 1e-6)\n",
        "\n",
        "    msk = (msk > 0.5).astype('float32')[..., np.newaxis]\n",
        "\n",
        "    validation_images2.append(img)\n",
        "    validation_masks2.append(msk)\n",
        "\n",
        "validation_images2 = np.stack(validation_images2)\n",
        "validation_masks2  = np.stack(validation_masks2)\n",
        "\n",
        "print(\"Val X:\", validation_images2.shape)\n",
        "print(\"Val y:\", validation_masks2.shape)"
      ],
      "metadata": {
        "id": "Q-ri02gENVSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== \"OG-style\" preprocessing ADAPTED TO 256×256 ====\n",
        "\n",
        "# Train\n",
        "for i in range(len(training_images2)):\n",
        "    # same as OG: ensure float32\n",
        "    training_images2[i] = training_images2[i].astype('float32')\n",
        "    # OG did .T because original was (4, H, W).\n",
        "    # Your images are already (H, W, C), so DO NOT transpose.\n",
        "\n",
        "for i in range(len(training_masks2)):\n",
        "    training_masks2[i] = training_masks2[i].astype('float32')\n",
        "    # OG did reshape(1,512,512,1).T; here masks are already (256,256,1), so no transpose/reshape needed.\n",
        "\n",
        "# If you have validation / test arrays loaded similarly:\n",
        "validation_images2  = np.stack(validation_images2)   # (N_val,256,256,4)\n",
        "validation_masks2   = np.stack(validation_masks2)    # (N_val,256,256,1)\n",
        "test_images2        = np.stack(test_images2)         # (N_test,256,256,4)\n",
        "test_masks2         = np.stack(test_masks2)          # (N_test,256,256,1)\n",
        "\n",
        "for i in range(len(validation_images2)):\n",
        "    validation_images2[i] = validation_images2[i].astype('float32')\n",
        "\n",
        "for i in range(len(validation_masks2)):\n",
        "    validation_masks2[i] = validation_masks2[i].astype('float32')\n",
        "\n",
        "for i in range(len(test_images2)):\n",
        "    test_images2[i] = test_images2[i].astype('float32')\n",
        "\n",
        "for i in range(len(test_masks2)):\n",
        "    test_masks2[i] = test_masks2[i].astype('float32')\n",
        "\n",
        "# Final reshapes – OG had (-1,512,512,4); we keep same idea but with 256:\n",
        "training_images2   = training_images2.reshape(-1, 256, 256, 4)\n",
        "training_masks2    = training_masks2.reshape(-1, 256, 256, 1)\n",
        "validation_images2 = validation_images2.reshape(-1, 256, 256, 4)\n",
        "validation_masks2  = validation_masks2.reshape(-1, 256, 256, 1)\n",
        "test_images2       = test_images2.reshape(-1, 256, 256, 4)\n",
        "test_masks2        = test_masks2.reshape(-1, 256, 256, 1)\n",
        "\n",
        "print(\"Train X final:\", training_images2.shape)\n",
        "print(\"Train y final:\", training_masks2.shape)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 2. FUNCTION TO SHOW A TRAIN IMAGE AS RGB (B4,B3,B2)\n",
        "# -----------------------------\n",
        "\n",
        "def show_train_example(idx):\n",
        "    img  = training_images2[idx]        # (256,256,4)\n",
        "    mask = training_masks2[idx][...,0]  # (256,256)\n",
        "\n",
        "    # Build RGB (Sentinel-2 True Colour)\n",
        "    # B4 = Red (index 2)\n",
        "    # B3 = Green (index 1)\n",
        "    # B2 = Blue (index 0)\n",
        "    rgb = img[..., [2,1,0]]\n",
        "\n",
        "    # Normalise for display\n",
        "    rgb_disp = (rgb - rgb.min()) / (rgb.max() + 1e-6)\n",
        "\n",
        "    plt.figure(figsize=(12,5))\n",
        "\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(rgb_disp)\n",
        "    plt.title(f\"Training Image #{idx} (RGB)\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(rgb_disp)\n",
        "    plt.imshow(mask, alpha=0.4, cmap=\"Blues\")\n",
        "    plt.title(\"RGB + Mask Overlay\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 3. SHOW EXAMPLE IMAGE\n",
        "# -----------------------------\n",
        "\n",
        "show_train_example(20)   # change index freely\n"
      ],
      "metadata": {
        "id": "z_9YTxo7NA5u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}